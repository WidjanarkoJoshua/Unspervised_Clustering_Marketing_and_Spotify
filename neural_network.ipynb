{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import random  \n",
    "from sklearn.mixture import GaussianMixture    \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.preprocessing import (LabelEncoder, FunctionTransformer, StandardScaler, \n",
    "                                   MinMaxScaler, RobustScaler, OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.model_selection import (train_test_split, learning_curve, GridSearchCV, \n",
    "                                     LeaveOneOut)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from scipy import stats\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marketing_df=pd.read_csv(\"marketing_campaign.csv\",sep=\"\\t\") \n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marketing Campaign \n",
    "# Creating are \"target class\"\n",
    "marketing_df['AcceptedAny'] = (marketing_df[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',\"Response\"]].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# One hot encoding marital status\n",
    "relationship_dict = {\n",
    "    'Single': 0,\n",
    "    'Together': 1,\n",
    "    'Married': 1,\n",
    "    'Divorced':0,\n",
    "    'Widow': 0,\n",
    "    'Alone': 0,\n",
    "    'Absurd': 0,\n",
    "    'YOLO': 0\n",
    "}\n",
    "\n",
    "marketing_df['Marital_Status'] = marketing_df['Marital_Status'].map(relationship_dict)\n",
    "\n",
    "\n",
    "# Target Encoding for Education \n",
    "education_mapping = {\n",
    "    'Basic': 0, \n",
    "    'Graduation': 1, \n",
    "    \"2n Cycle\":2,\n",
    "    \"Master\":2,\n",
    "    \"Phd\":3}\n",
    "\n",
    "\n",
    "# transforming thet amount to being what is the distribution of their porchases money wise\n",
    "marketing_df['Education'] = marketing_df['Education'].map(education_mapping)\n",
    "\n",
    "\n",
    "marketing_df[\"Kidhome\"]=marketing_df[\"Kidhome\"]+marketing_df['Teenhome']\n",
    "\n",
    "\n",
    "# Creating the 'birth_eras' column based on the bins\n",
    "marketing_df['birth_eras'] =  2014 - marketing_df['Year_Birth']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "marketing_df['NumAllPurchases'] = marketing_df['NumWebPurchases']+marketing_df['NumCatalogPurchases']+marketing_df['NumStorePurchases']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Marketing Removal Of Uneeded \n",
    "marketing_df.drop(columns=[\"ID\",'NumDealsPurchases', 'NumWebPurchases',\n",
    "       'NumCatalogPurchases', 'NumStorePurchases', \"Year_Birth\",\"Teenhome\",\"Recency\",\"Dt_Customer\",'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5','Response',\"Z_CostContact\",\"Z_Revenue\"],axis =1,inplace=True) \n",
    "marketing_df.dropna(inplace=True)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\"Income\"]\n",
    "\n",
    "# Calculate Z-scores only for the selected columns\n",
    "z_scores = np.abs(stats.zscore(marketing_df[columns_to_check]))\n",
    "\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "# Keep only rows where the Z-scores for the selected columns are below the threshold\n",
    "marketing_df = marketing_df[(z_scores < threshold).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_marketing= marketing_df.drop(columns=['AcceptedAny'])\n",
    "y_marketing=marketing_df['AcceptedAny']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Scaling Preproccesor for X Values\n",
    "standard_categories = ['bpm']\n",
    "\n",
    "percentage_categories = [ 'danceability_%', 'energy_%', 'acousticness_%', \n",
    "                      'instrumentalness_%', 'liveness_%']\n",
    "\n",
    "# Define the transformers\n",
    "\n",
    "def divide_by_100(X):\n",
    "    return X / 100 \n",
    "\n",
    "scaling_pipeline = Pipeline(steps=[\n",
    "    ('standard_scaling', RobustScaler()),  \n",
    "    ('min_max_scaling', MinMaxScaler())     \n",
    "])\n",
    "\n",
    "preprocessor_spotify = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standard', scaling_pipeline, standard_categories), \n",
    "        ('percentage', scaling_pipeline, percentage_categories), \n",
    "         \n",
    "    ], \n",
    "    remainder='passthrough', \n",
    "    force_int_remainder_cols=False  \n",
    ")\n",
    "\n",
    "# Scaling categories (Based on Training/Testing)\n",
    "standard_categories = ['Education', 'Income', 'Kidhome', 'MntWines',\n",
    "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "       'MntGoldProds', 'NumAllPurchases', 'NumWebVisitsMonth',\"birth_eras\"\n",
    "       ]  \n",
    "\n",
    "preprocessor_marketing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standard', scaling_pipeline, standard_categories),   \n",
    "           \n",
    "    ], \n",
    "    remainder='passthrough', \n",
    "    force_int_remainder_cols=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_marketing_model(n_features=25, activation_function=\"relu\", learning_rate=.0001, num_neurons=128, layers=5):\n",
    "    model = Sequential()\n",
    "\n",
    "    \n",
    "    model.add(Dense(num_neurons, activation=activation_function, input_shape=(n_features,), kernel_initializer=HeNormal())) \n",
    "\n",
    "    for a in range(layers - 1): \n",
    "        # Prevent num_neurons from becoming too small (<= 1)\n",
    "        if num_neurons > 8:\n",
    "            num_neurons = max(num_neurons // 2, 2)  # Ensure neurons don't go below 2\n",
    "        model.add(Dense(num_neurons, activation=activation_function, kernel_initializer=HeNormal()))  # Apply He Normal\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=HeNormal()))  # Sigmoid output layer\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='binary_crossentropy',  \n",
    "                  metrics=[\"accuracy\",\"precision\",\"recall\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18794881b40>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_marketing, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = preprocessor_marketing.fit_transform(X_train)\n",
    "X_test = preprocessor_marketing.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "marketing_model_swish = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "marketing_model_swish.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=marketing_model_swish.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[229,  19],\n",
       "       [ 46,  53]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_confusion=confusion_matrix(y_test, y_pred)   \n",
    "base_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network With Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a pipeline and get components\n",
    "def get_components(preproccessor,dim_reduction_method, X):\n",
    "    # Apply preprocessing and dimensionality reduction\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preproccessor),  \n",
    "        ('dim_reduction', dim_reduction_method)  \n",
    "    ])\n",
    "    \n",
    "\n",
    "    pipeline.fit(X)\n",
    "    \n",
    "\n",
    "    transformed_data = pipeline.transform(X)\n",
    "    return transformed_data \n",
    "\n",
    " \n",
    "pca = PCA(n_components=8,random_state=42)  \n",
    "rp = GaussianRandomProjection(n_components=11,random_state=42)  \n",
    "ica = FastICA(n_components=4,random_state=42) \n",
    "\n",
    "transformed_pca_marketing = get_components(preprocessor_marketing,pca, x_marketing)\n",
    "transformed_rp_marketing = get_components(preprocessor_marketing,rp, x_marketing)\n",
    "transformed_ica_marketing = get_components(preprocessor_marketing,ica, x_marketing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[230,  18],\n",
       "       [ 53,  46]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_pca_marketing, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create models for each activation function\n",
    "\n",
    "marketing_model_swish_pca = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "# Train models with early stopping\n",
    "\n",
    "marketing_model_swish_pca.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0)  \n",
    "\n",
    "y_pred=marketing_model_swish_pca.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int) \n",
    "pca_confusion=confusion_matrix(y_test, y_pred)   \n",
    "pca_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[229,  19],\n",
       "       [ 60,  39]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ICA\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_ica_marketing, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create models for each activation function\n",
    "\n",
    "marketing_model_swish_ica = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "# Train models with early stopping\n",
    "\n",
    "marketing_model_swish_ica.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0)  \n",
    "\n",
    "y_pred=marketing_model_swish_ica.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int) \n",
    "ica_confusion=confusion_matrix(y_test, y_pred)   \n",
    "ica_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[231,  17],\n",
       "       [ 57,  42]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rp\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_rp_marketing, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create models for each activation function\n",
    "\n",
    "marketing_model_swish_rp = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "# Train models with early stopping\n",
    "\n",
    "marketing_model_swish_rp.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0)  \n",
    "\n",
    "y_pred=marketing_model_swish_rp.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int) \n",
    "rp_confusion=confusion_matrix(y_test, y_pred)   \n",
    "rp_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting cluster labels \n",
    "\n",
    "pipeline_kmeans_marketing = Pipeline([\n",
    "    ('preprocessor', preprocessor_marketing),  \n",
    "    ('kmeans', KMeans(n_clusters=3,init='k-means++',max_iter=200, n_init=50,random_state=42,algorithm=\"elkan\"))  \n",
    "]) \n",
    "\n",
    "pipeline_gmm_marketing = Pipeline([\n",
    "    ('preprocessor', preprocessor_marketing),  \n",
    "    ('gmm', GaussianMixture(n_components=3,init_params='kmeans',max_iter=200,n_init=50,random_state=42))  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kmeans_marketing.fit(x_marketing) \n",
    "labels_kmeans=pipeline_kmeans_marketing.predict(x_marketing)\n",
    "\n",
    "\n",
    "pipeline_gmm_marketing.fit(x_marketing) \n",
    "labels_gmm=pipeline_gmm_marketing.predict(x_marketing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([610, 711, 410]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_kmeans,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([570, 610, 551]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_gmm,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1731, 15)\n",
      "(1731, 3)\n"
     ]
    }
   ],
   "source": [
    "labels_kmeans = labels_kmeans.reshape(-1)  \n",
    "labels_gmm = labels_gmm.reshape(-1) \n",
    " \n",
    "\n",
    " # Convert numpy array to pandas Series\n",
    "df_kmeans = pd.Series(labels_kmeans)\n",
    "df_gmm = pd.Series(labels_gmm)\n",
    "\n",
    "# One-hot encode using get_dummies\n",
    "one_hot_kmeans_df = pd.get_dummies(df_kmeans, prefix='cluster').astype(int)\n",
    "one_hot_gmm_df = pd.get_dummies(df_gmm, prefix='cluster').astype(int)\n",
    "  \n",
    "\n",
    "print(marketing_df.shape)\n",
    "print(one_hot_gmm_df.shape)\n",
    "\n",
    "marketing_df_kmeans = pd.concat([x_marketing.reset_index(drop=True), one_hot_kmeans_df], axis=1)\n",
    "\n",
    "marketing_df_gmm = pd.concat([x_marketing.reset_index(drop=True), one_hot_gmm_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[230,  18],\n",
       "       [ 53,  46]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gmm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(marketing_df_gmm, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = preprocessor_marketing.fit_transform(X_train)\n",
    "X_test = preprocessor_marketing.transform(X_test)\n",
    "\n",
    "\n",
    "marketing_model_swish_gmm = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "marketing_model_swish_gmm.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0)  \n",
    "\n",
    "y_pred=marketing_model_swish_gmm.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int) \n",
    "gmm_confusion=confusion_matrix(y_test, y_pred)   \n",
    "gmm_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshu\\OneDrive\\Documents\\GitHub\\cs-7641-2025-spring-jwidjanarko3\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[236,  12],\n",
       "       [ 55,  44]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kmeans\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(marketing_df_kmeans, y_marketing, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = preprocessor_marketing.fit_transform(X_train)\n",
    "X_test = preprocessor_marketing.transform(X_test)\n",
    "\n",
    "# Create models for each activation function\n",
    "\n",
    "marketing_model_swish_kmeans = create_marketing_model(n_features=len(X_train[0]),activation_function=\"swish\",num_neurons=256)\n",
    "\n",
    "\n",
    "\n",
    "# Train models with early stopping\n",
    "\n",
    "marketing_model_swish_kmeans.fit(X_train, y_train, epochs=200, batch_size=64, \n",
    "                                            verbose=0)  \n",
    "\n",
    "y_pred=marketing_model_swish_kmeans.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(int) \n",
    "kmeans_confusion=confusion_matrix(y_test, y_pred)   \n",
    "kmeans_confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
